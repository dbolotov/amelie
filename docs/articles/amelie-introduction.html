<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Amelie Introduction • amelie</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><meta property="og:title" content="Amelie Introduction">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">amelie</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/amelie-introduction.html">Amelie Introduction</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Amelie Introduction</h1>
            
          </div>

    
    
<div class="contents">
<div id="introduction" class="section level3">
<h3 class="hasAnchor">
<a href="#introduction" class="anchor"></a>Introduction</h3>
<p>This vignette describes the anomaly detection algorithm and provides some examples.</p>
</div>
<div id="description" class="section level3">
<h3 class="hasAnchor">
<a href="#description" class="anchor"></a>Description</h3>
<p>The anomaly detection problem is set up here as a binary classification task, where each observation <span class="math inline">\(x\)</span> is classified as anomalous (class <code>1</code>) or non-anomalous (class <code>0</code>). We assume that anomalies are much less frequent than normal observations.</p>
<p>The scoring method is as follows. Given an observation <span class="math inline">\(x\)</span> consisting of features <span class="math inline">\(\{x_1, ..., x_n\}\)</span>, compute the probability density <span class="math inline">\(p(x)\)</span> of the features. If the <span class="math inline">\(p(x) &lt; \epsilon\)</span>, where <span class="math inline">\(\epsilon\)</span> is a tuned parameter, the observation is classified as anomalous.</p>
</div>
<div id="concepts" class="section level3">
<h3 class="hasAnchor">
<a href="#concepts" class="anchor"></a>Concepts</h3>
<div id="univariate-normal-distribution" class="section level4">
<h4 class="hasAnchor">
<a href="#univariate-normal-distribution" class="anchor"></a>Univariate normal distribution</h4>
<p>In the univariate case, each of the features <span class="math inline">\(x_i\)</span> is assumed to be normally distributed with mean <span class="math inline">\(\mu_i\)</span> and variance <span class="math inline">\(\sigma_i^2\)</span>: <span class="math inline">\(x_i \sim \mathcal{N}(\mu_i,\sigma_i^2)\)</span>.</p>
<p>For a variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, the probability density is given by:</p>
<p><span class="math display">\[p(x; \mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\]</span></p>
</div>
<div id="parameter-estimation" class="section level4">
<h4 class="hasAnchor">
<a href="#parameter-estimation" class="anchor"></a>Parameter estimation</h4>
<p>The univariate normal distribution is parametrized by mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. For a data set <span class="math inline">\(\{x_1,x_2, ..., x_m\}\)</span>, the parameters are estimated using maximum likelihood:</p>
<p><span class="math display">\[\mu = \frac{1}{m}\sum_{i=1}^{m}x_i\]</span> <span class="math display">\[\sigma^2 = \frac{1}{m}\sum_{i=1}^{m}(x_i-\mu)^2\]</span></p>
</div>
<div id="density-estimation" class="section level4">
<h4 class="hasAnchor">
<a href="#density-estimation" class="anchor"></a>Density estimation</h4>
<p>For the univariate case, the joint probability density is calculated under the assumptions that features are independent of each other, and each feature is normally distributed. For a set of observations <span class="math inline">\(\{x_1,x_2, ..., x_m\}\)</span> where each observation <span class="math inline">\(x_i \in R^n\)</span>, the joint probability then is a product of the individual densities:</p>
<p><span class="math display">\[p(x) = \prod_{j=1}^{n}p(x_j;\mu_j,\sigma_j^2)\]</span></p>
</div>
</div>
<div id="algorithm" class="section level3">
<h3 class="hasAnchor">
<a href="#algorithm" class="anchor"></a>Algorithm</h3>
<p>Using the above assumptions and definitions, the algorithm is implemented as follows:</p>
<ol style="list-style-type: decimal">
<li>Given a data set <span class="math inline">\((x,y)\)</span>, split it into training and cross-validation sets, <span class="math inline">\(\{x^{(1)},...,x^{(m)}\}\)</span> and <span class="math inline">\(\{(x_{cv}^{(1)},y_{cv}^{(1)}), ..., (x_{cv}^{(k)},y_{cv}^{(k)})\}\)</span>.
<ul>
<li>The training set is not required to have any positive (anomalous) examples.</li>
<li>It is a good idea to set aside a separate test data set before the call to <code>anode</code>, for final evaluation.</li>
</ul>
</li>
<li>Fit model <span class="math inline">\(p(x)_{train}\)</span> on training set.
<ol style="list-style-type: lower-alpha">
<li>Fit parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> for each feature.</li>
<li>Calculate <span class="math inline">\(p(x)_{train}\)</span> for each row in training set.</li>
</ol>
</li>
<li>Tune <span class="math inline">\(\epsilon\)</span> on cross-validation data set.
<ol style="list-style-type: lower-alpha">
<li>Pick starting value for <span class="math inline">\(\epsilon\)</span>.</li>
<li>Calculate <span class="math inline">\(p(x)_{cv}\)</span> for each row in CV set using <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> from <code>step 2</code>.</li>
<li>For each row <span class="math inline">\(i\)</span> in CV set, predict <span class="math inline">\(y = 1\)</span> if <span class="math inline">\(p(x_i) &lt; \epsilon\)</span> (anomaly), else predict <span class="math inline">\(y=0\)</span>.</li>
<li>Evaluate prediction accuracy on CV set using F1 score.</li>
<li>Update <span class="math inline">\(\epsilon\)</span> if F1 score improves.</li>
<li>Stop when best <span class="math inline">\(\epsilon\)</span> value is found.</li>
</ol>
</li>
<li>Evaluate algorithm accuracy on the training set.
<ul>
<li>Use <span class="math inline">\(p(x)_{train}\)</span> from <code>step 2</code> and <span class="math inline">\(\epsilon\)</span> from <code>step 3</code>.</li>
</ul>
</li>
<li>After training, evaluate algorithm accuracy on a separate test set.
<ul>
<li>Compute <span class="math inline">\(p(x_i)_{test}\)</span> using <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> from <code>step 2</code> and <span class="math inline">\(\epsilon\)</span> from <code>step 3</code>.</li>
</ul>
</li>
</ol>
</div>
<div id="extending-the-univariate-anomaly-detection-algorithm" class="section level3">
<h3 class="hasAnchor">
<a href="#extending-the-univariate-anomaly-detection-algorithm" class="anchor"></a>Extending the univariate anomaly detection algorithm</h3>
<p>It is possible to extend the above algorithm by using multivariate version of the normal distribution. In this case, the features are not assumed to be independent, and <span class="math inline">\(p\)</span> is not a product of independent densities.</p>
<div id="multivariate-normal-distribution" class="section level4">
<h4 class="hasAnchor">
<a href="#multivariate-normal-distribution" class="anchor"></a>Multivariate normal distribution</h4>
<p>For parameters <span class="math inline">\(\mu \in R^n\)</span> and <span class="math inline">\(\Sigma \in R^{n * n}\)</span>, the multivariate probability density function is given by:</p>
<p><span class="math display">\[p(x; \mu, \Sigma) = \frac{1}{(2\pi)^{n/2}|\Sigma|^{1/2}}e^{(-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu))}\]</span></p>
</div>
</div>
<div id="examples" class="section level3">
<h3 class="hasAnchor">
<a href="#examples" class="anchor"></a>Examples</h3>
<p>Create a small data set and train the algorithm using formula notation and matrix notation:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(amelie)
x1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">1</span>,.<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">1</span>,<span class="dv">1</span>,.<span class="dv">7</span>,<span class="op">-</span><span class="dv">2</span>,<span class="op">-</span><span class="dv">1</span>)
x2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,.<span class="dv">5</span>,<span class="dv">0</span>,.<span class="dv">4</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="op">-</span>.<span class="dv">3</span>,<span class="op">-</span>.<span class="dv">1</span>)
x &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind,<span class="kw">list</span>(x1,x2))
y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">1</span>)
dframe &lt;-<span class="st"> </span><span class="kw">data.frame</span>(x,y)

df_fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/ad.html">ad</a></span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, dframe)

mat_fit &lt;-<span class="st"> </span><span class="kw"><a href="../reference/ad.html">ad</a></span>(<span class="dt">x =</span> x, <span class="dt">y =</span> y)</code></pre></div>
</div>
<div id="references" class="section level3">
<h3 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h3>
<p><a href="https://www.coursera.org/learn/machine-learning">Machine Learning Course</a> - the package is based on anomaly detection lectures from Andrew Ng’s Machine Learning course.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Dmitriy Bolotov.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
